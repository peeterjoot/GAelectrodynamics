%
% Copyright Â© 2018 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{

An important example of the generalized dot product is the dot product of a vector and bivector.
Unlike the dot product of two vectors, a vector-bivector dot product is order dependent.

The vector dot product is zero when the two vectors are normal.
This is also true if the vector and bivector are normal, that is, having no common factor, as in
\begin{equation}\label{eqn:generalizedDot_vectorBivector:661}
\Be_1 \cdot \Be_{23} = \gpgradeone{ \Be_{123} } = 0.
\end{equation}

On the other hand, a non-zero vector-bivector dot product requires the vector to have some overlap with the bivector.
A bivector formed from the product of two normal vectors \( B = \Ba \Bb, \, \Ba \cdot \Bb = 0 \), will have a non-zero dot product with any vector that lies in \( \Span \setlr{ \Ba, \Bb} \)
\begin{dmath}\label{eqn:generalizedDot_vectorBivector:682}
\lr{ \alpha \Ba + \beta \Bb } \cdot (\Ba\Bb)
=
\alpha \Norm{\Ba}^2 \Bb - \beta \Norm{\Bb}^2 \Ba.
\end{dmath}

It is often useful to be able to expand a vector-bivector dot product.
A useful identity for such an expansion is

\maketheorem{Dot product of vector and wedge product.}{thm:generalizedDot:wedgeDotDistribution}{
The dot product of a vector and a wedge product of two vectors distributes as
\begin{equation*}
\Ba \cdot \lr{ \Bb \wedge \Bc }
=
\lr{ \Bc \wedge \Bb } \cdot \Ba
=
( \Ba \cdot \Bb ) \Bc
-( \Ba \cdot \Bc ) \Bb.
\end{equation*}
} % theorem

Before proving this theorem, let's take a look at what it implies.  
This shows that only vectors with some component in the span of the plane represented by the bivector will result in a non-zero vector-bivector dot product.
We also know that when a vector that lies entirely in the span of a bivector is multiplied by that bivector, the result is rotated by \( \pm \pi/2 \).
This means that a vector-bivector dot product is normal to the vector that is dotted with the bivector.
This can also be seen algebraically since
\begin{dmath}\label{eqn:generalizedDot_vectorBivector:1120}
\Ba \cdot \lr{ \Ba \cdot \lr{ \Bb \wedge \Bc }}
=
\Ba \cdot \lr{ ( \Ba \cdot \Bb ) \Bc -( \Ba \cdot \Bc ) \Bb }
=
\lr{ \Ba \cdot \Bc } \lr{ \Ba \cdot \Bb } - \lr{ \Ba \cdot \Bc } \lr{ \Ba \cdot \Bb }
= 0.
\end{dmath}

The net effect of a vector-bivector dot product is to select only components of the vector that lie in the plane of the bivector, and then to rotate those by \( \pm \pi/2 \) in that plane, plus scale that rotated vector by the magnitude of bivector.

There are (somewhat tricky) coordinate free ways to prove
\cref{thm:generalizedDot:wedgeDotDistribution}
, but a dumber simple expansion in coordinates also does the job.
\begin{dmath}\label{eqn:generalizedDot_vectorBivector:681}
\begin{aligned}
\Ba \cdot \lr{ \Bb \wedge \Bc } &= \sum_{i, j, k} a_i b_j c_k \Be_i \cdot (\Be_j \wedge \Be_k)
= \sum_{i, j \ne k} a_i b_j c_k \gpgradeone{ \Be_i \Be_j \Be_k }
\\
\lr{ \Bc \wedge \Bb } \cdot \Ba &= \sum_{i, j, k} a_i b_j c_k (\Be_k \wedge \Be_j) \cdot \Be_i
= \sum_{i, j \ne k} a_i b_j c_k \gpgradeone{ \Be_k \Be_j \Be_i }.
\end{aligned}
\end{dmath}

If all of \( i, j, k \) are unique then \( \gpgradeone{ \Be_i \Be_j \Be_k } = 0 \), so the vector selection is non-zero only when \( i \) equals one of \( j, k \).
For example
\begin{dmath}\label{eqn:generalizedDot_vectorBivector:1040}
\begin{aligned}
\gpgradeone{ \Be_1 \Be_1 \Be_2 } &= \Be_2 \\
\gpgradeone{ \Be_1 \Be_2 \Be_1 } &= -\Be_1.
\end{aligned}
\end{dmath}

Given \( j \ne k \), and \( i = j \) or \( i = k \),  then it is simple to show
(\cref{problem:generalizedDot:distributionUnitVectorsa})
that
\begin{equation}\label{eqn:generalizedDot_vectorBivector:1020}
\gpgradeone{ \Be_i \Be_j \Be_k }
= \gpgradeone{ \Be_k \Be_j \Be_i },
\end{equation}
so \( \Ba \cdot \lr{ \Bb \wedge \Bc } = \lr{ \Bc \wedge \Bb } \cdot \Ba \).
Additionally
(\cref{problem:generalizedDot:distributionUnitVectorsb})
\begin{equation}\label{eqn:generalizedDot_vectorBivector:980}
\gpgradeone{ \Be_i \Be_j \Be_k }
=
\Be_k \lr{ \Be_j \cdot \Be_i }
-\Be_j \lr{ \Be_k \cdot \Be_i }.
\end{equation}

Plugging \cref{eqn:generalizedDot_vectorBivector:980} back into \cref{eqn:generalizedDot_vectorBivector:681} proves the theorem
\begin{dmath}\label{eqn:generalizedDot_vectorBivector:1060}
\Ba \cdot \lr{ \Bb \wedge \Bc }
= \sum_{i, j, k} a_i b_j c_k \lr{ \Be_k \lr{ \Be_j \cdot \Be_i }
-\Be_j \lr{ \Be_k \cdot \Be_i } }
=
\lr{ \Ba \cdot \Bb } \Bc
- \lr{ \Ba \cdot \Bc } \Bb.
\end{dmath}

The RHS of \cref{eqn:generalizedDot_vectorBivector:1060} shows that the vector-bivector dot product has the following relation to the
\R{3} triple cross product

\maketheorem{Triple cross product.}{thm:generalizedDot:tripleCross}{
For vectors in \R{3}, the dot product of a vector and vector wedge product can be expressed as a triple cross product
\begin{equation*}
\Ba \cdot \lr{ \Bb \wedge \Bc }
=
\lr{ \Bb \cross \Bc } \cross \Ba.
\end{equation*}
} % theorem

This can be proven by invoking the well known
identity for the triple cross product
(\citep{jackson1975cew})
\begin{dmath}\label{eqn:generalizedDot_vectorBivector:1100}
\Ba \cross ( \Bb \cross \Bc ) = (\Ba \cdot \Bc) \Bb - (\Ba \cdot \Bb) \Bc.
\end{dmath}

Alternatively, it can be proven directly by applying the identity \( \Ba \wedge \Bb = I ( \Ba \cross \Bb ) \) to the vector-bivector product, and then selecting the vector grade
\begin{dmath}\label{eqn:generalizedDot_vectorBivector:1000}
\Ba \lr{ \Bb \wedge \Bc }
=
\Ba I \lr{ \Bb \cross \Bc }
=
I \lr{ \Ba \cdot \lr{ \Bb \cross \Bc } }
+
I \lr{ \Ba \wedge \lr{ \Bb \cross \Bc } }
=
I \lr{ \Ba \cdot \lr{ \Bb \cross \Bc } }
+
I^2 \Ba \cross \lr{ \Bb \cross \Bc }
=
I \lr{ \Ba \cdot \lr{ \Bb \cross \Bc } }
+
\lr{ \Bb \cross \Bc } \cross \Ba.
\end{dmath}

This multivector has a pseudoscalar (grade 3) component, and a vector component, so selecting the grade one component proves the theorem
\begin{equation}\label{eqn:generalizedDot_vectorBivector:1080}
\gpgradeone{ \Ba \lr{ \Bb \wedge \Bc } }
=
\Ba \cdot \lr{ \Bb \wedge \Bc }
=
\lr{ \Bb \cross \Bc } \cross \Ba.
\end{equation}
%}
