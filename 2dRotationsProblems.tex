%
% Copyright Â© 2017 Peeter Joot.  All Rights Reserved.
% Licenced as described in the file LICENSE under the root directory of this GIT repository.
%
%{
\makeproblem{\R{2} rotations.}{problem:2dRotations:1}{
Using familiar methods, such as rotation matrices, show that the counterclockwise and clockwise rotations of
\cref{eqn:2dRotations:280} are given by
\cref{eqn:2dRotations:300} and
\cref{eqn:2dRotations:3} respectively.
} % problem
\makeanswer{problem:2dRotations:1}{
The 2D rotation matrix is
\begin{equation}\label{eqn:2dRotations:1380}
R_\theta =
\begin{bmatrix}
   \cos\theta & -\sin\theta \\
   \sin\theta & \cos\theta
\end{bmatrix},
\end{equation}
so to rotate coordinates by \(\pm\pi/2\), we multiply by
\begin{equation}\label{eqn:2dRotations:1400}
R_{\pm\pi/2} = \pm
\begin{bmatrix}
   0 & -1 \\
   1 & 0
\end{bmatrix}.
\end{equation}
In particular
\begin{equation}\label{eqn:2dRotations:1420}
   R_{\pm\pi/2}
\begin{bmatrix}
   \rho \cos\theta \\
   \rho \sin\theta
\end{bmatrix}
   = \pm \pi/2
\begin{bmatrix}
   0 & -1 \\
   1 & 0
\end{bmatrix}
\begin{bmatrix}
   \rho \cos\theta \\
   \rho \sin\theta
\end{bmatrix}
=
\pm
\rho
\begin{bmatrix}
-\sin\theta \\
\cos\theta
\end{bmatrix},
\end{equation}
consistent with the results observed from left and right multiplication with the plane pseudoscalar \( \Be_1 \Be_2 \).
}
\makeproblem{Multivector Euler's formula and trig relations.}{problem:2dRotations:Euler}{
For a multivector \( x \) assume an infinite series representation of the exponential, sine and cosine functions and their hyperbolic analogues
\begin{equation*}
\begin{aligned}
e^x &= \sum_{k = 0}^\infty \frac{x^k}{k!} \\
\cos x &= \sum_{k = 0}^\infty (-1)^k \frac{x^{2k}}{(2k)!} \qquad \sin x = \sum_{k = 0}^\infty (-1)^k \frac{x^{2k+1}}{(2k+1)!} \\
\cosh x &= \sum_{k = 0}^\infty \frac{x^{2k}}{(2k)!} \qquad \sinh x = \sum_{k = 0}^\infty \frac{x^{2k+1}}{(2k+1)!} \\
\end{aligned}
\end{equation*}
\makesubproblem{}{problem:2dRotations:Euler:a}
Show that for scalar \( \theta \), and any multivectors \( J \) that satisfies \( J^2 = -1 \), and \( K^2 = 1 \), then
hold for multivectors \( J, K \) satisfying \( J^2 = -1 \) and \( K^2 = 1 \) respectively.
\begin{equation*}
\begin{aligned}
\cosh (J \theta ) &= \cos \theta, \quad \cosh (K \theta ) = \cosh \theta \\
\sinh (J \theta ) &= J \sin \theta, \quad \sinh (K \theta ) = K \sinh \theta.
\end{aligned}
\end{equation*}
\makesubproblem{}{problem:2dRotations:Euler:c}
Show that the trigonometric and hyperbolic Euler formulas
\begin{equation*}
\begin{aligned}
e^{ J \theta } &= \cos \theta + J \sin \theta \\
e^{ K \theta } &= \cosh \theta + K \sinh \theta,
\end{aligned}
\end{equation*}
hold for multivectors \( J, K \) satisfying \( J^2 = -1 \) and \( K^2 = 1 \) respectively.
\makesubproblem{}{problem:2dRotations:Euler:b}
Given multivectors \( X, Y \), show that \( e^{ X + Y } = e^{ X } e^{ Y } \) if \( X, Y \) commute.  That is \( X Y = Y X \).
} % problem
\makeanswer{problem:2dRotations:Euler}{
\makesubanswer{}{problem:2dRotations:Euler:a}
Let \( \chi \) be a multivector that squares to \( \pm 1 \).  Series expansion of \( \cosh(\chi \theta) \), for scalar \(theta\) yields
\begin{equation}\label{eqn:2dRotations:1440}
\cosh(\chi\theta)
= \sum_{k = 0}^\infty \frac{\lr{ \chi \theta }^{2k}}{(2k)!}
= \sum_{k = 0}^\infty \frac{ \chi^{2k} \theta^{2k} }{(2k)!}.
\end{equation}
In particular, for \( \chi = J, K \) respectively, we have
\begin{equation}\label{eqn:2dRotations:1460}
\begin{aligned}
\cosh\lr{J\theta} &= \sum_{k = 0}^\infty \frac{ \lr{-1}^k \theta^{2k} }{(2k)!} = \cos \theta \\
\cosh\lr{K\theta} &= \sum_{k = 0}^\infty \frac{ \lr{+1}^k \theta^{2k} }{(2k)!} = \cosh \theta.
\end{aligned}
\end{equation}
Similarly,
\begin{equation}\label{eqn:2dRotations:1480}
\sinh(\chi\theta)
= \sum_{k = 0}^\infty \frac{\lr{ \chi \theta }^{2k+1}}{(2k+1)!}
= \chi \sum_{k = 0}^\infty \frac{ \chi^{2k} \theta^{2k+1} }{(2k+1)!}.
\end{equation}
So, for \( \chi = J, K \) respectively, we have
\begin{equation}\label{eqn:2dRotations:1500}
\begin{aligned}
\sinh\lr{J\theta} &= J \sum_{k = 0}^\infty \frac{ \lr{-1}^k \theta^{2k+1} }{(2k +1)!} = J \sin \theta \\
\sinh\lr{K\theta} &= K \sum_{k = 0}^\infty \frac{ \lr{+1}^k \theta^{2k+1} }{(2k +1)!} = K \sinh \theta.
\end{aligned}
\end{equation}
\makesubanswer{}{problem:2dRotations:Euler:c}
Series expanding again, we may split the exponential into even and odd parts, for any multivector \( x \)
\begin{equation}\label{eqn:2dRotations:1520}
\begin{aligned}
e^x
&=
\sum_{k = 0}^\infty \frac{x^k}{k!} \\
&=
\sum_{k = 0}^\infty \frac{x^{2k}}{(2k)!}
+
\sum_{k = 0}^\infty \frac{x^{2k+1}}{(2k+1)!} \\
&=
\cosh( x ) + \sinh(x).
\end{aligned}
\end{equation}
There is nothing in such a series expansion that cares about the type of \( x \), only that we can take repeated powers.  The remainder of the problem follows from our results above after substitution of \( x = J \theta \) and \( x = K \theta \) respectively.
\makesubanswer{}{problem:2dRotations:Euler:b}
The exponential of a sum, such as \( X + Y \), regardless of the types or characteristics of \( X \) and \( Y \) is
\begin{equation}\label{eqn:2dRotations:1540}
e^{X + Y}
= \sum_{k = 0}^\infty \frac{\lr{X + Y}^k}{k!}.
\end{equation}
Let's look at the powers of such a sum.  For the square and cube we have
\begin{equation}\label{eqn:2dRotations:1560}
\lr{ X + Y}^2 = X^2 + X Y + Y X + Y^2,
\end{equation}
\begin{equation}\label{eqn:2dRotations:1580}
\lr{ X + Y}^3 = X^3 + X^2 Y + X Y X + Y X^2 + Y^2 X + Y X Y + X Y^2 + Y^3.
\end{equation}
Observe that the conventional binomial series form for these powers is only possible if \( X \) and \( Y \) commute.  If we have such commutation, then the exponential takes the form
\begin{equation}\label{eqn:2dRotations:1600}
\begin{aligned}
e^{X + Y}
&= \sum_{k = 0}^\infty \sum_{j = 0}^k \binom{k}{j} \frac{X^j Y^{k-j}}{k!} \\
%&= \sum_{k = 0}^\infty \sum_{j = 0}^k \frac{k!}{j!(k - j)!} \frac{X^j Y^k}{k!} \\
&= \sum_{k = 0}^\infty \sum_{j = 0}^k \frac{X^j Y^{k-j}}{j!(k - j)!}.
\end{aligned}
\end{equation}
This is a sum over all points in a trianglular region of the first quadrant of indexes on the \( k, j \) axes.
%in \cref{fig:exponentialOfSum:exponentialOfSumFig1}
We can, however, sum over all the diagonals \( s = k - j = \textrm{constant} \), and index our position on each of those diagonals by \( u = j \), to find
\begin{equation}\label{eqn:2dRotations:1620}
\begin{aligned}
e^{X + Y}
&= \sum_{s = 0}^\infty \sum_{u = 0}^\infty \frac{X^u Y^{s}}{u!s!} \\
&= \sum_{u = 0}^\infty \frac{X^u}{u!}
   \sum_{s = 0}^\infty \frac{Y^s}{s!} \\
&= e^X e^Y.
\end{aligned}
\end{equation}
We see that commutation of variables is required for an exponential of a sum to equal the product of the exponentials.  This is worth understanding since it shows us that we can factor exponentials of sums such as \( Z = 1 + \Be_1 \Be_2 \), \( Z = \Be_1 \Be_2 + \Be_3 \Be_4 \), \( Z = \Be_1 + \Be_1 \Be_2 \Be_3 \), into the product of the exponentials of the summands of those multivectors, but cannot do so with multivectors like \( Z = \Be_1 + \Be_2 \), \( Z = \Be_1 + \Be_1 \Be_2 \), or \( Z = \Be_1 \Be_2 + \Be_2 \Be_3 \).
}
%}
